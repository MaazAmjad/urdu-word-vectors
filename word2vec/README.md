# Pre-trained Urdu word2vec models 


## Web News Dataset (skipgram 2019-04-07)

We trained this on huge News dataset. The model knows {vocab_size} different Urdu words.

**Linguistic Preprocessing**: split into sentences, tokenized

**Parameters**: {"alpha": 0.05, "hs": 0, "iter": 15, "min_count": 50, "negative": 20, "sample": 0.0001, "sg": 1, "size": 300, "window": 5}

#### Model Performance:

- Google Analogy: **48%**

[Download](Link to the model) (*51 Mbytes*)
